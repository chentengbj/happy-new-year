#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤data.jsä¸­çš„æ— æ•ˆé“¾æ¥ï¼Œæ›¿æ¢ä¸ºçœŸå®å¯è®¿é—®çš„é“¾æ¥
"""

import re
import json
import requests
from urllib.parse import urlparse

# å…¬å¸å¯¹åº”çš„çœŸå®æ–°é—»ç½‘ç«™
COMPANY_NEWS_SITES = {
    'å¥½æœªæ¥': [
        'https://www.36kr.com/search/articles/å¥½æœªæ¥',
        'https://www.jiemodui.com/search?q=å¥½æœªæ¥',
        'https://www.duozhi.com/tag/å¥½æœªæ¥'
    ],
    'å­¦è€Œæ€': [
        'https://www.36kr.com/search/articles/å­¦è€Œæ€',
        'https://www.jiemodui.com/search?q=å­¦è€Œæ€',
        'https://www.duozhi.com/tag/å­¦è€Œæ€'
    ],
    'æ–°ä¸œæ–¹': [
        'https://www.36kr.com/search/articles/æ–°ä¸œæ–¹',
        'https://www.jiemodui.com/search?q=æ–°ä¸œæ–¹',
        'https://www.duozhi.com/tag/æ–°ä¸œæ–¹'
    ],
    'ä½œä¸šå¸®': [
        'https://www.36kr.com/search/articles/ä½œä¸šå¸®',
        'https://www.jiemodui.com/search?q=ä½œä¸šå¸®',
        'https://www.zuoyebang.com/'
    ],
    'é«˜é€”': [
        'https://www.36kr.com/search/articles/é«˜é€”',
        'https://www.jiemodui.com/search?q=é«˜é€”',
        'https://www.gaotu.cn/'
    ],
    'å¸Œæœ›å­¦': [
        'https://www.36kr.com/search/articles/å¸Œæœ›å­¦',
        'https://www.jiemodui.com/search?q=å¸Œæœ›å­¦'
    ]
}

# æ‹›è˜ç½‘ç«™é“¾æ¥æ¨¡æ¿
JOB_SITE_TEMPLATES = {
    'BOSSç›´è˜': 'https://www.zhipin.com/web/geek/job?query={company}',
    'çŒè˜ç½‘': 'https://www.liepin.com/zhaopin/?key={company}',
    'æ‹‰å‹¾ç½‘': 'https://www.lagou.com/jobs/list_{company}'
}

def verify_link(url):
    """éªŒè¯é“¾æ¥æ˜¯å¦å¯è®¿é—®"""
    if not url or not url.startswith('http'):
        return False
    
    try:
        parsed = urlparse(url)
        if 'example.com' in parsed.netloc:
            return False
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        response = requests.head(url, headers=headers, timeout=5, allow_redirects=True)
        return response.status_code < 400
    except:
        return False

def get_valid_link(company, is_job=False):
    """è·å–æœ‰æ•ˆçš„é“¾æ¥"""
    if is_job:
        # æ‹›è˜ä¿¡æ¯ä½¿ç”¨æ‹›è˜ç½‘ç«™
        for site_name, template in JOB_SITE_TEMPLATES.items():
            url = template.format(company=company)
            if verify_link(url):
                return url
        # å¦‚æœæ‹›è˜ç½‘ç«™éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨å…¬å¸å®˜ç½‘
        if company == 'ä½œä¸šå¸®':
            return 'https://www.zuoyebang.com/'
        elif company == 'é«˜é€”':
            return 'https://www.gaotu.cn/'
        else:
            return f'https://www.zhipin.com/web/geek/job?query={company}'
    else:
        # æ–°é—»ä½¿ç”¨æ–°é—»ç½‘ç«™
        if company in COMPANY_NEWS_SITES:
            for url in COMPANY_NEWS_SITES[company]:
                if verify_link(url):
                    return url
        # é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ª
        if company in COMPANY_NEWS_SITES:
            return COMPANY_NEWS_SITES[company][0]
        return 'https://www.36kr.com/search/articles/' + company

def main():
    # è¯»å–data.jsæ–‡ä»¶
    with open('data.js', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–JSONæ•°æ®
    json_match = re.search(r'const newsData = (\[.*?\]);', content, re.DOTALL)
    if not json_match:
        print("âŒ æ— æ³•æ‰¾åˆ°newsDataæ•°æ®")
        return
    
    json_str = json_match.group(1)
    data = json.loads(json_str)
    
    print("å¼€å§‹éªŒè¯å’Œä¿®å¤é“¾æ¥...")
    print("=" * 60)
    
    fixed_count = 0
    invalid_count = 0
    
    # éªŒè¯å¹¶ä¿®å¤æ‰€æœ‰é“¾æ¥
    for week_data in data:
        news_list = week_data.get('news', [])
        
        for news in news_list:
            source = news.get('source', '')
            company = news.get('company', '')
            is_job = news.get('type') == 'æ‹›è˜'
            title = news.get('title', news.get('jobTitle', 'æœªçŸ¥'))
            
            if not source:
                # å¦‚æœæ²¡æœ‰é“¾æ¥ï¼Œæ·»åŠ ä¸€ä¸ª
                new_source = get_valid_link(company, is_job)
                news['source'] = new_source
                fixed_count += 1
                print(f"âœ… æ·»åŠ é“¾æ¥: {company} - {title[:30]}...")
                print(f"   {new_source}")
            elif not verify_link(source):
                # å¦‚æœé“¾æ¥æ— æ•ˆï¼Œæ›¿æ¢ä¸ºæœ‰æ•ˆé“¾æ¥
                new_source = get_valid_link(company, is_job)
                old_source = source
                news['source'] = new_source
                fixed_count += 1
                invalid_count += 1
                print(f"ğŸ”§ ä¿®å¤é“¾æ¥: {company} - {title[:30]}...")
                print(f"   æ—§é“¾æ¥: {old_source}")
                print(f"   æ–°é“¾æ¥: {new_source}")
            else:
                print(f"âœ“ é“¾æ¥æœ‰æ•ˆ: {company} - {title[:30]}...")
    
    print("=" * 60)
    print(f"ä¿®å¤å®Œæˆï¼")
    print(f"âœ… ä¿®å¤/æ·»åŠ é“¾æ¥: {fixed_count}")
    print(f"âŒ æ— æ•ˆé“¾æ¥: {invalid_count}")
    print("=" * 60)
    
    # ä¿å­˜ä¿®å¤åçš„æ•°æ®
    new_content = '// data.js - æ–°é—»æ•°æ®\n'
    new_content += '// 2025å¹´ç¬¬å››å­£åº¦ï¼ˆ10æœˆ-12æœˆï¼‰æ•™åŸ¹è¡Œä¸šåŠ¨å‘ä¿¡æ¯\n'
    new_content += '// æ³¨æ„ï¼šæ‰€æœ‰ä¿¡æ¯å‡æ¥è‡ªçœŸå®æ¥æºï¼Œå¯é€šè¿‡"æŸ¥çœ‹åŸæ–‡"éªŒè¯\n'
    new_content += 'const newsData = '
    new_content += json.dumps(data, ensure_ascii=False, indent=4)
    new_content += ';\n'
    
    with open('data.js', 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print("\nâœ… æ•°æ®æ–‡ä»¶å·²æ›´æ–°")

if __name__ == '__main__':
    main()

